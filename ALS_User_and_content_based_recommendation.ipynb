{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "9nDWm3UuqshV",
        "outputId": "2710f06e-7975-468a-df75-09465091331e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f56d1d09-5d62-43b6-b60c-94062f667b7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f56d1d09-5d62-43b6-b60c-94062f667b7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tags.csv to tags.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtA_v2URNLFQ",
        "outputId": "a3ad3fe1-968f-43d9-f07a-e0586e62b536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=dcfd1e515bf37edc70975143495186b8311084a23c0193d3d97a5cbbaafe8db9\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-kIWVlEkRsV",
        "outputId": "315776d9-58fd-4a4c-8f78-5de26e2f1fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml import Pipeline\n",
        "import findspark"
      ],
      "metadata": {
        "id": "EeUT6qRr6t-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "UnksP4qWkkpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"MovieRecommendationSystem\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "Henozz_U6t7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pfdmyaBDfQb8",
        "outputId": "b29734c1-5857-4189-d781-7da233dfbf0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7eda60e29d80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8fd729863840:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MovieRecommendationSystem</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies=spark.read.csv('/content/drive/MyDrive/Bigdata/movies.csv',header=True,inferSchema=True)\n",
        "movies.printSchema()\n",
        "movies.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM-8EsEf6t4d",
        "outputId": "a1cc08b7-5894-44ee-a843-c8ac611b2f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings=spark.read.csv('/content/drive/MyDrive/Bigdata/ratings.csv',header=True,inferSchema=True)\n",
        "# Drop unnecessary columns\n",
        "ratings = ratings.drop(\"timestamp\")\n",
        "\n",
        "ratings.printSchema()\n",
        "ratings.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jT5Dghe694d",
        "outputId": "1763ffd3-8720-43f8-a763-bb7d48ad4378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            "\n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|     1|      1|   4.0|\n",
            "|     1|      3|   4.0|\n",
            "|     1|      6|   4.0|\n",
            "|     1|     47|   5.0|\n",
            "|     1|     50|   5.0|\n",
            "+------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings=movies.join(ratings,'movieId',\"inner\")\n",
        "movie_ratings.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kXSDGYGdyF8",
        "outputId": "808ad6b4-659b-4d4b-bb79-8f009002cdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+------+------+\n",
            "|movieId|               title|              genres|userId|rating|\n",
            "+-------+--------------------+--------------------+------+------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|     1|   4.0|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|     1|   4.0|\n",
            "|      6|         Heat (1995)|Action|Crime|Thri...|     1|   4.0|\n",
            "|     47|Seven (a.k.a. Se7...|    Mystery|Thriller|     1|   5.0|\n",
            "|     50|Usual Suspects, T...|Crime|Mystery|Thr...|     1|   5.0|\n",
            "|     70|From Dusk Till Da...|Action|Comedy|Hor...|     1|   3.0|\n",
            "|    101|Bottle Rocket (1996)|Adventure|Comedy|...|     1|   5.0|\n",
            "|    110|   Braveheart (1995)|    Action|Drama|War|     1|   4.0|\n",
            "|    151|      Rob Roy (1995)|Action|Drama|Roma...|     1|   5.0|\n",
            "|    157|Canadian Bacon (1...|          Comedy|War|     1|   5.0|\n",
            "+-------+--------------------+--------------------+------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = movie_ratings.randomSplit([0.75, 0.25], seed=42)"
      ],
      "metadata": {
        "id": "Xtv14ULtl9uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.evaluation import RankingEvaluator\n",
        "\n",
        "def get_similarities(train_data,test_data):\n",
        "    genres_indexer = StringIndexer(inputCol=\"genres\", outputCol=\"genresIndex\")\n",
        "    #********************User Based****************************\n",
        "    # Create a vector assembler\n",
        "    # Create a vector assembler\n",
        "    feature_cols = [\"userId\", \"movieId\"]\n",
        "    # Drop the existing \"features\" column if it exists\n",
        "    if \"features\" in train_data.columns:\n",
        "        train_data = train_data.drop(\"features\")\n",
        "\n",
        "    # Create a vector assembler\n",
        "    vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "    #ratings = vector_assembler.transform(ratings)\n",
        "    #ratings.show()\n",
        "    # Create an ALS model\n",
        "    als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "\n",
        "    # Create a pipeline\n",
        "    pipeline = Pipeline(stages=[genres_indexer,vector_assembler, als])\n",
        "\n",
        "\n",
        "    # Fit the pipeline to the data\n",
        "    model = pipeline.fit(train_data)\n",
        "\n",
        "    # Extract unique user IDs\n",
        "    users = train_data.select(\"userId\").distinct()\n",
        "\n",
        "    # Generate user similarity matrix\n",
        "    user_similarities = model.stages[-1].userFactors.alias(\"u1\").crossJoin(model.stages[-1].userFactors.alias(\"u2\"))\n",
        "    # Select the desired columns\n",
        "    user_similarities = user_similarities.select(col(\"u1.id\").alias(\"u1\"),\n",
        "    col(\"u1.features\").alias(\"u1_features\"),\n",
        "    col(\"u2.id\").alias(\"u2\"),\n",
        "    col(\"u2.features\").alias(\"u2_features\"))\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions = model.transform(test_data)\n",
        "\n",
        "    # Evaluate the model using RMSE as an example\n",
        "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "    print(\"User Based\")\n",
        "    print(f\"nRoot Mean Squared Error (RMSE): {rmse}\")\n",
        "    evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "    mse = evaluator.evaluate(predictions)\n",
        "    print(\"\\nMean Squared Error (MSE) on test data: {}\".format(mse))\n",
        "\n",
        "\n",
        "\n",
        "    #evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "    #mae = evaluator.evaluate(predictions)\n",
        "    #print(\"Mean Average Error (MAE) on test data: {}\".format(mae))\n",
        "    #evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "    #r2 = evaluator.evaluate(predictions)\n",
        "    #print(\"Co efficient of dtermination (R2) on test data: {}\".format(r2))\n",
        "\n",
        "    #user_similarities.show()\n",
        "\n",
        "    # Fit the pipeline to the data\n",
        "    #movie_model = pipeline.fit(movies)\n",
        "\n",
        "\n",
        "\n",
        "    #******************Content based *************************\n",
        "\n",
        "    # Create indexers for user and movie IDs\n",
        "     # Create a StringIndexer for the 'genres' column\n",
        "\n",
        "    transformed_movies = genres_indexer.fit(train_data).transform(train_data)\n",
        "\n",
        "     # Create a vector assembler for content features\n",
        "    feature_col_content = [ \"genresIndex\"]\n",
        "    vector_assembler = VectorAssembler(inputCols=feature_col_content, outputCol=\"features\")\n",
        "\n",
        "    # Transform the movies DataFrame using the indexers and vector assembler\n",
        "    transformed_movies = vector_assembler.transform(transformed_movies)\n",
        "    #transformed_movies.show()\n",
        "    #Step 2: Train ALS Model\n",
        "    als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "\n",
        "    # Create a pipeline\n",
        "    pipeline = Pipeline(stages=[als])\n",
        "\n",
        "    # Fit the pipeline to the data\n",
        "    model_content = pipeline.fit(train_data)\n",
        "    # Make predictions on the test set\n",
        "    predictions = model_content.transform(test_data)\n",
        "\n",
        "    # Evaluate the model using RMSE as an example\n",
        "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "    print(\"Content Based\")\n",
        "    print(\"\\nRoot Mean Squared Error (RMSE)on test data: {}\".format(rmse))\n",
        "\n",
        "    evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "    mse = evaluator.evaluate(predictions)\n",
        "    print(\"\\nMean Squared Error (MSE) on test data: {}\".format(mse))\n",
        "\n",
        "    #evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "    #mae = evaluator.evaluate(predictions)\n",
        "    #print(\"Mean Average Error (MAE) on test data: {}\".format(mae))\n",
        "    #evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "    #r2 = evaluator.evaluate(predictions)\n",
        "    #print(\"Co efficient of dtermination (R2) on test data: {}\".format(r2))\n",
        "\n",
        "\n",
        "    # Step 3: Generate Content Similarity Matrix\n",
        "    # Extract unique Movie IDs with features\n",
        "    content = transformed_movies.select(\"movieId\", \"features\").distinct()\n",
        "\n",
        "    # Generate content similarity matrix\n",
        "    content_similarities = content.alias(\"m1\").crossJoin(content.alias(\"m2\")).filter(\"m1.movieId != m2.movieId\").select(\n",
        "       col(\"m1.movieId\").alias(\"m1\"),\n",
        "       col(\"m1.features\").alias(\"m1_features\"),\n",
        "      col(\"m2.movieId\").alias(\"m2\"),\n",
        "      col(\"m2.features\").alias(\"m2_features\"))\n",
        "\n",
        "    #content_similarities.show()\n",
        "    return user_similarities,content_similarities\n",
        "\n"
      ],
      "metadata": {
        "id": "5Mp97aYo691o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Define a UDF to calculate cosine similarity\n",
        "def calculate_cosine_similarity(features1, features2):\n",
        "    dense_vector1 = DenseVector(features1)\n",
        "    dense_vector2 = DenseVector(features2)\n",
        "\n",
        "    dot_product = dense_vector1.dot(dense_vector2)\n",
        "    norm_product = dense_vector1.norm(2) * dense_vector2.norm(2)\n",
        "\n",
        "    similarity = dot_product / norm_product if norm_product != 0 else 0.0\n",
        "    return float(similarity)\n",
        "\n",
        "\n",
        "def get_user_cosine_similarity(train_data,test_data):\n",
        "    # Register the UDF\n",
        "    cosine_similarity_udf = udf(calculate_cosine_similarity, DoubleType())\n",
        "    user_similarities,_=get_similarities(train_data,test_data)\n",
        "    #user_similarities.show()\n",
        "    # Assuming you have a DataFrame named user_similarities with columns\n",
        "      # \"u1.features\" and \"u2.features\"\n",
        "    # The features columns are assumed to be of type list\n",
        "\n",
        "    # Calculate cosine similarity and add a new column\n",
        "    user_similarities_with_similarity = user_similarities.withColumn(\"cosineSimilarity\",\n",
        "        cosine_similarity_udf(col(\"u1_features\"), col(\"u2_features\")))\n",
        "\n",
        "    # Show the resulting DataFrame\n",
        "    #user_similarities_with_similarity.show()\n",
        "\n",
        "    return user_similarities_with_similarity\n"
      ],
      "metadata": {
        "id": "mh5Gb4Y-WGgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "def colabrative_filering(userId,num_movies,train_data,test_data):\n",
        "    # Assuming you have a DataFrame named user_similarities\n",
        "    target_user_id = userId\n",
        "    user_similarities_with_cosine=get_user_cosine_similarity(train_data,test_data)\n",
        "    # Filter user similarities for the target user\n",
        "    target_user_similarities = user_similarities_with_cosine.filter(\n",
        "        col(\"u1\") == target_user_id)\n",
        "    # Get movies watched by the target user\n",
        "    target_user_movies = train_data.filter(col(\"userId\") == target_user_id).select(\"movieId\",\"rating\")\n",
        "\n",
        "    #target_user_similarities.show()\n",
        "    # Filter rows with cosineSimilarity greater than 0.8\n",
        "    similar_users = user_similarities_with_cosine.filter(col(\n",
        "        \"cosineSimilarity\") > 0.8)\n",
        "    # Show the resulting DataFrame\n",
        "    #similar_users.show()\n",
        "\n",
        "\n",
        "    # Get movies watched by similar users\n",
        "    movies_watched_by_similar_users = similar_users.join(ratings.alias(\"m\"),\n",
        "                col(\"u2\") == col(\"m.userId\")).select(\"m.movieId\",\"m.rating\")\n",
        "    movies_watched_by_similar_users = movies_watched_by_similar_users.filter(col(\n",
        "        \"rating\") > 2.5)\n",
        "    # Get movies not watched by the target user but watched by similar users\n",
        "    recommended_movies_id = movies_watched_by_similar_users.join(\n",
        "           target_user_movies, on=\"movieId\", how=\"left_anti\")\n",
        "\n",
        "    # Show the recommended movies\n",
        "    #recommended_movies_id.show()\n",
        "    # Join recommended movies with movie titles\n",
        "    recommended_movies = recommended_movies_id.join(\n",
        "              movies, on=\"movieId\")\n",
        "    #recommended_movies=recommended_movies.orderBy(col(\"rating\").desc())\n",
        "    # Show the recommended movies with titles\n",
        "    #recommended_movies.show()\n",
        "\n",
        "    return recommended_movies.limit(num_movies)\n",
        "\n"
      ],
      "metadata": {
        "id": "506Ak6Et69u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content_cosine_similarity(train_data,test_data):\n",
        "    # Register the UDF\n",
        "    cosine_similarity_udf = udf(calculate_cosine_similarity, DoubleType())\n",
        "    _,content_similarities=get_similarities(train_data,test_data)\n",
        "    #user_similarities.show()\n",
        "    # Assuming you have a DataFrame named user_similarities with columns\n",
        "      # \"u1.features\" and \"u2.features\"\n",
        "    # The features columns are assumed to be of type list\n",
        "\n",
        "    # Calculate cosine similarity and add a new column\n",
        "    content_similarities_with_cosine = content_similarities.withColumn(\"cosineSimilarity\",\n",
        "        cosine_similarity_udf(col(\"m1_features\"), col(\"m2_features\")))\n",
        "    # Select relevant columns\n",
        "    #content_similarities_with_cosine = content_similarities_with_cosine.select(\"m1\", \"m2\", \"cosineSimilarity\")\n",
        "\n",
        "\n",
        "    # Show the resulting DataFrame\n",
        "    #content_similarities_with_cosine.show()\n",
        "\n",
        "    return content_similarities_with_cosine\n"
      ],
      "metadata": {
        "id": "8grGYxIeYmzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,desc\n",
        "def content_based_recommendation(userId,num_movies,train_data,test_data):\n",
        "\n",
        "    target_user_id = userId\n",
        "\n",
        "    #get content based similarities\n",
        "    content_similarities_with_cosine=get_content_cosine_similarity(train_data,test_data)\n",
        "    #content_similarities_with_cosine.show()\n",
        "\n",
        "\n",
        "    # Get genres of movies watched by the target user\n",
        "    user_watched_genres = train_data.filter(col(\"userId\") == target_user_id).select(\"genres\")\n",
        "\n",
        "    # Extract unique genres\n",
        "    unique_genres = set(user_watched_genres.rdd.flatMap(lambda row: row[0].split(\"|\")).collect())\n",
        "\n",
        "    # Show the unique genres\n",
        "    print(\"Unique Genres:\", unique_genres)\n",
        "\n",
        "    # Filter movies with at least one common genre\n",
        "    similar_movies_genres = train_data.filter(\n",
        "       (col(\"userId\") != target_user_id) &\n",
        "       (col(\"genres\").isNotNull()) &\n",
        "       (col(\"genres\") != \"\") &\n",
        "       (col(\"genres\").isin(list(unique_genres)))).select(\"title\", \"genres\").distinct()\n",
        "\n",
        "    # Show the similar movies based on genres\n",
        "    #similar_movies_genres.show()\n",
        "\n",
        "    return similar_movies_genres.limit(num_movies)\n"
      ],
      "metadata": {
        "id": "qqNC4S5TX8ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gmHgZbSufp5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3BtRV9Efp0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UI for user input\n",
        "def get_user_input():\n",
        "    target_user_id = int(input(\"Enter the user ID: \"))\n",
        "    num_movies = int(input(\"Enter the number of movies to recommend: \"))\n",
        "    return target_user_id, num_movies"
      ],
      "metadata": {
        "id": "UzKm8mDbEMzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main():\n",
        "    user_id, num_movies = get_user_input()\n",
        "    recommendations = colabrative_filering(user_id, num_movies,train_data,test_data)\n",
        "    # Print a message before showing the collabrative results\n",
        "    print(\"\\nUser Based Recommendation:\\n\")\n",
        "    recommendations.show()\n",
        "    content_recommendation=content_based_recommendation(user_id, num_movies,train_data,test_data)\n",
        "    print(\"\\n Content Based Recommendation:\\n\")\n",
        "    content_recommendation.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BTHKd4jGGto0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTFOVB0VGudQ",
        "outputId": "70f2a65d-8dab-4d3f-b898-308302b90bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the user ID: 12\n",
            "Enter the number of movies to recommend: 15\n",
            "User Based\n",
            "nRoot Mean Squared Error (RMSE): 0.8859522380886061\n",
            "\n",
            "Mean Squared Error (MSE) on test data: 0.7849113681742101\n",
            "Content Based\n",
            "\n",
            "Root Mean Squared Error (RMSE)on test data: 0.8859522380886061\n",
            "\n",
            "Mean Squared Error (MSE) on test data: 0.7849113681742101\n",
            "\n",
            "User Based Recommendation:\n",
            "\n",
            "+-------+------+--------------------+--------------------+\n",
            "|movieId|rating|               title|              genres|\n",
            "+-------+------+--------------------+--------------------+\n",
            "|  84374|   3.5|No Strings Attach...|      Comedy|Romance|\n",
            "|  56367|   3.5|         Juno (2007)|Comedy|Drama|Romance|\n",
            "|   6942|   4.0|Love Actually (2003)|Comedy|Drama|Romance|\n",
            "|  51705|   4.5|Priceless (Hors d...|      Comedy|Romance|\n",
            "|  81847|   3.5|      Tangled (2010)|Animation|Childre...|\n",
            "|   3578|   4.0|    Gladiator (2000)|Action|Adventure|...|\n",
            "|  95543|   3.5|Ice Age 4: Contin...|Adventure|Animati...|\n",
            "|  66203|   3.5|He's Just Not Tha...|Comedy|Drama|Romance|\n",
            "|   7154|   4.0|Mona Lisa Smile (...|       Drama|Romance|\n",
            "|   5377|   3.5|  About a Boy (2002)|Comedy|Drama|Romance|\n",
            "|   7458|   5.0|         Troy (2004)|Action|Adventure|...|\n",
            "|   7153|   4.0|Lord of the Rings...|Action|Adventure|...|\n",
            "| 103339|   4.0|White House Down ...|Action|Drama|Thri...|\n",
            "| 112006|   4.0|Tangled Ever Afte...|Action|Animation|...|\n",
            "|   8869|   5.0|First Daughter (2...|      Comedy|Romance|\n",
            "+-------+------+--------------------+--------------------+\n",
            "\n",
            "User Based\n",
            "nRoot Mean Squared Error (RMSE): 0.8859522380886061\n",
            "\n",
            "Mean Squared Error (MSE) on test data: 0.7849113681742101\n",
            "Content Based\n",
            "\n",
            "Root Mean Squared Error (RMSE)on test data: 0.8859522380886061\n",
            "\n",
            "Mean Squared Error (MSE) on test data: 0.7849113681742101\n",
            "Unique Genres: {'Romance', 'Sci-Fi', 'Comedy', 'Drama', 'Thriller', 'Adventure', 'Fantasy', 'Action'}\n",
            "\n",
            " Content Based Recommendation:\n",
            "\n",
            "+--------------------+--------+\n",
            "|               title|  genres|\n",
            "+--------------------+--------+\n",
            "|     Whatever (1998)|   Drama|\n",
            "|Pink Flamingos (1...|  Comedy|\n",
            "|Erin Brockovich (...|   Drama|\n",
            "|Porky's Revenge (...|  Comedy|\n",
            "|    MacArthur (1977)|   Drama|\n",
            "|Intolerance: Love...|   Drama|\n",
            "|Let's Go to Priso...|  Comedy|\n",
            "|The Duke of Burgu...|   Drama|\n",
            "|Rock the Kasbah (...|  Comedy|\n",
            "|Awfully Big Adven...|   Drama|\n",
            "|        Blink (1994)|Thriller|\n",
            "|  Airport '77 (1977)|   Drama|\n",
            "|Angela's Ashes (1...|   Drama|\n",
            "|  Let It Ride (1989)|  Comedy|\n",
            "|Chasing Papi (a.k...|  Comedy|\n",
            "+--------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "tJ4QRo6hjb4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25mv9wpVp2aG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}